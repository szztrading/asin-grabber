
# app.py â€” Competitor ASIN Grabber (Streamlit standalone)
import os, re, requests
import pandas as pd
import streamlit as st
from bs4 import BeautifulSoup
from datetime import datetime
import requests

# è¯»å– API Key
API_KEY = st.secrets["keepa"]["api_key"]

def search_products_by_keyword(keyword, domain=3, page=0):
    """è°ƒç”¨ Keepa æœç´¢åŠŸèƒ½ï¼ŒæŠ“å–å…³é”®è¯ä¸‹çš„ç«å“ ASIN"""
    url = "https://api.keepa.com/query"
    params = {
        "key": API_KEY,
        "domain": domain,  # 3 = UK, 1 = US, 4 = DE ...
        "type": "product",
        "term": keyword,
        "page": page
    }
    res = requests.get(url, params=params).json()
    if "products" not in res:
        st.error("âŒ Keepa è¿”å›é”™è¯¯: " + str(res))
        return pd.DataFrame()
    
    # è§£ææ•°æ®
    products = []
    for p in res["products"]:
        products.append({
            "ASIN": p.get("asin"),
            "Title": p.get("title"),
            "Brand": p.get("brand"),
            "Category": p.get("rootCategory"),
            "BuyBoxPrice": p.get("buyBoxPrice"),
            "SalesRank": p.get("salesRankDrops30"),  # 30å¤©é”€é‡æ’åæ³¢åŠ¨ï¼ˆè¶Šå¤šè¶Šå¥½ï¼‰
        })
    return pd.DataFrame(products)

# ğŸ“Š Streamlit UI
st.title("ğŸ” Keepa ç«å“åˆ†ææ¨¡å—")

keyword = st.text_input("è¾“å…¥å…³é”®è¯ï¼ˆä¾‹å¦‚ï¼šairlock æˆ– brewing heat padï¼‰")

if st.button("æŠ“å–ç«å“"):
    if not keyword:
        st.warning("è¯·è¾“å…¥å…³é”®è¯")
    else:
        df = search_products_by_keyword(keyword)
        st.dataframe(df)
        st.download_button("â¬‡ï¸ ä¸‹è½½ CSV", df.to_csv(index=False), "keepa_results.csv")


st.set_page_config(page_title="Competitor ASIN Grabber", layout="wide")
st.title("ğŸ•µï¸ Competitor ASIN Grabber")
st.caption("""
è¾“å…¥ä¸€ä¸ªç«å“ ASINï¼ˆå¦‚ B0D4QMBS75ï¼‰ï¼ŒæŠ“å–è¯¥å•†å“è¯¦æƒ…é¡µçš„ç›¸ä¼¼/ç›¸å…³æ¨èä½çš„ ASINï¼Œå°½é‡è¡¥å…¨æ ‡é¢˜/ä»·æ ¼/è¯„åˆ†/è¯„è®ºï¼Œå¹¶å¯¼å‡º CSVã€‚
å¦‚æœé…ç½®äº† Keepa API Keyï¼ˆ`KEEPA_API_KEY`ï¼‰ï¼Œä¼šä¼˜å…ˆä½¿ç”¨ Keepa è·å– alsoBought/alsoViewed å…³ç³»ã€‚
""")

# ----------------- Utils -----------------
def _format_price(txt):
    if txt is None: return None
    v = re.sub(r"[^\d\.,]", "", str(txt)).replace(",", "")
    try: return float(v)
    except: return None

def _fetch_mobile_product_snapshot(asin, domain="amazon.co.uk"):
    """
    è®¿é—®äºšé©¬é€Šç§»åŠ¨ç®€é¡µå°½é‡å–åˆ°ï¼šæ ‡é¢˜/ä»·æ ¼/æ˜Ÿçº§/è¯„è®ºæ•°ã€‚
    ä»…åšè¡¥å……ï¼Œä¸ä¿è¯100%è·å–ã€‚
    """
    url = f"https://{domain}/gp/aw/d/{asin}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Linux; Android 11) AppleWebKit/537.36 Mobile Safari/537.36",
        "Accept-Language": "en-GB,en;q=0.9",
    }
    try:
        r = requests.get(url, headers=headers, timeout=12)
        if r.status_code != 200:
            return {"asin": asin, "title": None, "price": None, "rating": None, "reviews": None, "url": f"https://{domain}/dp/{asin}"}
        soup = BeautifulSoup(r.text, "html.parser")

        title_el = soup.select_one("#title")
        title = title_el.get_text(strip=True) if title_el else None

        price = None
        price_el = soup.select_one(".a-color-price") or soup.select_one("#priceblock_ourprice")
        if price_el: price = _format_price(price_el.get_text())

        rating = None
        rating_el = soup.select_one(".acr-stars-text") or soup.find(string=re.compile(r"out of 5"))
        if rating_el:
            text = rating_el if isinstance(rating_el, str) else rating_el.get_text()
            m = re.search(r"([\d\.]+)\s*out of 5", text)
            if m:
                try: rating = float(m.group(1))
                except: rating = None

        reviews = None
        rev_el = soup.select_one("#acrCustomerReviewText") or soup.find(string=re.compile(r"ratings"))
        if rev_el:
            text = rev_el if isinstance(rev_el, str) else rev_el.get_text()
            m = re.search(r"([\d,]+)", text)
            if m: reviews = int(m.group(1).replace(",", ""))

        return {"asin": asin, "title": title, "price": price, "rating": rating, "reviews": reviews, "url": f"https://{domain}/dp/{asin}"}
    except Exception:
        return {"asin": asin, "title": None, "price": None, "rating": None, "reviews": None, "url": f"https://{domain}/dp/{asin}"}

def _scrape_related_asins_from_dp(asin, domain="amazon.co.uk", max_items=100):
    """
    ç›´æ¥æŠ“å–ç«å“è¯¦æƒ…é¡µï¼Œè§£ææ¨èä½é‡Œçš„ ASINï¼ˆsponsored/related/also viewedç­‰ï¼‰
    """
    url = f"https://{domain}/dp/{asin}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/123.0 Safari/537.36",
        "Accept-Language": "en-GB,en;q=0.9",
    }
    try:
        r = requests.get(url, headers=headers, timeout=12)
        if r.status_code != 200:
            return []
        soup = BeautifulSoup(r.text, "html.parser")

        asins = set([asin.upper()])
        # data-asin å®¹å™¨
        for tag in soup.find_all(attrs={"data-asin": True}):
            candidate = str(tag.get("data-asin")).strip().upper()
            if re.fullmatch(r"B0[A-Z0-9]{8}", candidate):
                asins.add(candidate)
        # é“¾æ¥å½¢å¼ /dp/B0XXXXXXX/
        for a in soup.find_all("a", href=True):
            m = re.search(r"/dp/(B0[A-Z0-9]{8})", a["href"].upper())
            if m: asins.add(m.group(1))

        asins.discard(asin.upper())
        out = list(asins)
        return out[:max_items]
    except Exception:
        return []

def _keepa_fetch_related(asin, domain="amazon.co.uk", api_key=None, max_items=200):
    """
    ä½¿ç”¨ Keepa API è·å– alsoBought/alsoViewed ç­‰å…³è”ASINï¼ˆæ›´ç¨³ã€æ›´å…¨ï¼‰
    ç¯å¢ƒå˜é‡ï¼šKEEPA_API_KEYï¼›pip install keepa
    """
    try:
        import keepa
    except Exception:
        return [], "Keepa SDK æœªå®‰è£…ï¼Œå·²å›é€€ HTML è§£ææ¨¡å¼ã€‚"

    if not api_key:
        return [], "æœªè®¾ç½® KEEPA_API_KEYï¼Œå·²å›é€€ HTML è§£ææ¨¡å¼ã€‚"

    try:
        api = keepa.Keepa(api_key)
        domain_map = {"amazon.co.uk": 2, "amazon.com": 1, "amazon.de": 3, "amazon.fr": 8, "amazon.it": 10, "amazon.es": 9}
        dom = domain_map.get(domain, 2)
        products = api.query(asin=asin, domain=dom, history=False)
        if not products:
            return [], "Keepa æœªè¿”å›äº§å“ï¼Œå›é€€ HTML è§£ææ¨¡å¼ã€‚"
        p = products[0]
        related = set()
        for k in ("alsoBought", "alsoViewed", "frequentlyBoughtTogether", "related"):
            arr = p.get(k) or []
            for x in arr:
                xu = str(x).upper()
                if re.fullmatch(r"B0[A-Z0-9]{8}", xu): related.add(xu)
        related.discard(asin.upper())
        return list(related)[:max_items], None
    except Exception as e:
        return [], f"Keepa æŸ¥è¯¢å¤±è´¥ï¼ˆ{e}ï¼‰ï¼Œå›é€€ HTML è§£ææ¨¡å¼ã€‚"

# ----------------- UI -----------------
with st.container():
    cols = st.columns([1,1,1,1])
    with cols[0]:
        domain = st.selectbox("Marketplace", ["amazon.co.uk","amazon.com","amazon.de","amazon.fr","amazon.it","amazon.es"], index=0)
    with cols[1]:
        seed_asin = st.text_input("è¾“å…¥ç«å“ ASINï¼ˆå¦‚ B0D4QMBS75ï¼‰").strip()
    with cols[2]:
        max_items = st.number_input("æœ€å¤šæŠ“å–æ•°é‡", 10, 500, 120, 10)
    with cols[3]:
        use_keepa = st.toggle("ä¼˜å…ˆä½¿ç”¨ Keepa API", value=True, help="éœ€åœ¨ Secrets æ·»åŠ  KEEPA_API_KEYï¼›æ— åˆ™è‡ªåŠ¨å›é€€ HTML è§£æã€‚")

if st.button("ğŸš€ å¼€å§‹æŠ“å–", use_container_width=True):
    if not re.fullmatch(r"[Bb]0[A-Za-z0-9]{8}", seed_asin or ""):
        st.error("è¯·è¾“å…¥åˆæ³•çš„ ASINï¼ˆä»¥ B0 å¼€å¤´ï¼Œå…±10å­—ç¬¦ï¼‰ã€‚")
    else:
        seed_asin = seed_asin.upper()

        # 1) å°è¯• Keepa
        related_asins, keepa_msg = [], None
        if use_keepa:
            keepa_key = os.environ.get("KEEPA_API_KEY", "").strip()
            related_asins, keepa_msg = _keepa_fetch_related(seed_asin, domain=domain, api_key=keepa_key, max_items=max_items)
        if keepa_msg: st.warning(keepa_msg)

        # 2) å›é€€ HTML è§£æ
        if not related_asins:
            with st.status("ğŸ” æ­£åœ¨è§£æç«å“è¯¦æƒ…é¡µæ¨èä½ â€¦", expanded=False):
                related_asins = _scrape_related_asins_from_dp(seed_asin, domain=domain, max_items=max_items)
                st.write(f"æ‰¾åˆ°å€™é€‰ ASINï¼š{len(related_asins)}")

        if not related_asins:
            st.error("æœªèƒ½æŠ“åˆ°ç›¸å…³ ASINï¼Œè¯·æ›´æ¢ç«å“æˆ–ç¨åå†è¯•ã€‚")
        else:
            rows, progress = [], st.progress(0, text="è¡¥å……ä¿¡æ¯ä¸­â€¦")
            for i, a in enumerate(related_asins, start=1):
                snap = _fetch_mobile_product_snapshot(a, domain=domain)
                rows.append(snap)
                progress.progress(int(i/len(related_asins)*100), text=f"ä¿¡æ¯è¡¥å…… {i}/{len(related_asins)}")
            progress.empty()

            df = pd.DataFrame(rows, columns=["asin","title","price","rating","reviews","url"])
            st.success(f"æŠ“å–å®Œæˆï¼šå…± {len(df)} æ¡ã€‚")
            st.dataframe(df, use_container_width=True)

            csv_data = df.to_csv(index=False).encode("utf-8-sig")
            today = datetime.now().strftime("%Y%m%d")
            st.download_button(
                "ğŸ“¥ ä¸‹è½½ CSV",
                data=csv_data,
                file_name=f"asin_competitors_{seed_asin}_{today}.csv",
                mime="text/csv",
                use_container_width=True
            )

st.markdown("---")
st.caption("æç¤ºï¼šè‹¥é…ç½® Keepaï¼Œç¨³å®šæ€§å’Œè¦†ç›–ç‡æ›´å¥½ï¼›æœªé…ç½®ä¹Ÿèƒ½æŠ“åˆ°ä¸€éƒ¨åˆ†æ¨è ASINï¼ˆåŸºäºé¡µé¢ç»“æ„è§£æï¼‰ã€‚")
