# app.py â€” Competitor ASIN Grabber (Keepa REST + HTML fallback + Relevance Scoring)
# åŠŸèƒ½ï¼š
# 1) è¾“å…¥ç«å“ ASIN â†’ é€šè¿‡ Keepa RESTï¼ˆä¼˜å…ˆï¼‰æˆ– HTML å›é€€æŠ“å– alsoBought/alsoViewed/related ASIN
# 2) ä¸ºæ¯ä¸ª ASIN å°½é‡è¡¥å…¨ Title/Price/Rating/Reviews/URL
# 3) ç›¸å…³æ€§æ‰“åˆ† + è¿‡æ»¤ï¼ˆåŒ…å«/æ’é™¤è¯ã€ä»·æ ¼ã€è¯„åˆ†ã€è¯„è®ºé˜ˆå€¼ï¼‰
# 4) å¯¼å‡ºä¸¤ä¸ª CSVï¼šå…¨é‡æŠ“å–ã€å·²è¿‡æ»¤æ¨è

import os
import re
import json
import requests
import pandas as pd
import streamlit as st
from bs4 import BeautifulSoup
from datetime import datetime  # âœ… æ­£ç¡®å¯¼å…¥

# ---------------- åŸºæœ¬è®¾ç½® ----------------
st.set_page_config(page_title="Competitor ASIN Grabber", layout="wide")
st.title("ğŸ•µï¸ Competitor ASIN Grabber")
st.caption("""
è¾“å…¥ä¸€ä¸ªç«å“ ASINï¼ˆå¦‚ B0D4QMBS75ï¼‰ï¼ŒæŠ“å–è¯¥å•†å“è¯¦æƒ…é¡µçš„ alsoBought / alsoViewed / relatedï¼Œå¹¶å°½é‡è¡¥å…¨æ ‡é¢˜/ä»·æ ¼/è¯„åˆ†/è¯„è®ºã€‚
âœ… è‹¥é…ç½® Keepaï¼ˆSecrets: `KEEPA_API_KEY` æˆ– `[keepa].api_key`ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨ Keepa RESTï¼›å¤±è´¥æˆ–æœªé…ç½®å°†å›é€€ HTML è§£æã€‚
""")

# ---------------- è¯»å– Keepa Keyï¼ˆå…¼å®¹å¤šç§å†™æ³•ï¼‰ ----------------
def get_keepa_key() -> str:
    """
    è¯»å– Keepa API Keyï¼ˆä¼˜å…ˆ secretsï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼‰ã€‚
    æ”¯æŒä¸¤ç§ secrets å†™æ³•ï¼š
      1) KEEPA_API_KEY = "..."
      2) [keepa] \n api_key = "..."
    """
    try:
        key = (
            st.secrets.get("KEEPA_API_KEY", "") or
            (st.secrets.get("keepa", {}) or {}).get("api_key", "") or
            os.environ.get("KEEPA_API_KEY", "")
        )
        return (key or "").strip()
    except Exception:
        return (os.environ.get("KEEPA_API_KEY", "") or "").strip()

KEEPA_KEY = get_keepa_key()

# ---------------- å·¥å…·å‡½æ•° ----------------
def _format_price(txt):
    if txt is None:
        return None
    v = re.sub(r"[^\d\.,]", "", str(txt)).replace(",", "")
    try:
        return float(v)
    except Exception:
        return None

def _fetch_mobile_product_snapshot(asin, domain="amazon.co.uk"):
    """
    è®¿é—®äºšé©¬é€Šç§»åŠ¨ç®€é¡µï¼Œå°½é‡å–åˆ°ï¼šæ ‡é¢˜/ä»·æ ¼/æ˜Ÿçº§/è¯„è®ºæ•°ã€‚
    å¤±è´¥æ—¶ä¹Ÿè¿”å›åŸºæœ¬ç»“æ„ä»¥ä¿è¯æµæ°´çº¿ä¸ä¸­æ–­ã€‚
    """
    url = f"https://{domain}/gp/aw/d/{asin}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Linux; Android 11) AppleWebKit/537.36 Mobile Safari/537.36",
        "Accept-Language": "en-GB,en;q=0.9",
    }
    try:
        r = requests.get(url, headers=headers, timeout=15)
        if r.status_code != 200:
            return {"asin": asin, "title": None, "price": None, "rating": None, "reviews": None, "url": f"https://{domain}/dp/{asin}"}
        soup = BeautifulSoup(r.text, "html.parser")

        title_el = soup.select_one("#title")
        title = title_el.get_text(strip=True) if title_el else None

        price = None
        price_el = soup.select_one(".a-color-price") or soup.select_one("#priceblock_ourprice")
        if price_el:
            price = _format_price(price_el.get_text())

        rating = None
        rating_el = soup.select_one(".acr-stars-text") or soup.find(string=re.compile(r"out of 5"))
        if rating_el:
            text = rating_el if isinstance(rating_el, str) else rating_el.get_text()
            m = re.search(r"([\d\.]+)\s*out of 5", text)
            if m:
                try:
                    rating = float(m.group(1))
                except Exception:
                    rating = None

        reviews = None
        rev_el = soup.select_one("#acrCustomerReviewText") or soup.find(string=re.compile(r"ratings"))
        if rev_el:
            text = rev_el if isinstance(rev_el, str) else rev_el.get_text()
            m = re.search(r"([\d,]+)", text)
            if m:
                reviews = int(m.group(1).replace(",", ""))

        return {"asin": asin, "title": title, "price": price, "rating": rating, "reviews": reviews, "url": f"https://{domain}/dp/{asin}"}
    except Exception:
        return {"asin": asin, "title": None, "price": None, "rating": None, "reviews": None, "url": f"https://{domain}/dp/{asin}"}

def _scrape_related_asins_from_dp(asin, domain="amazon.co.uk", max_items=120):
    """
    ç›´æ¥æŠ“å–ç«å“è¯¦æƒ…é¡µï¼Œè§£ææ¨èä½é‡Œçš„ ASINï¼ˆsponsored/related/also viewed ç­‰ï¼‰ã€‚
    ä½œä¸º Keepa ä¸å¯ç”¨æ—¶çš„å›é€€æ–¹æ¡ˆã€‚
    """
    url = f"https://{domain}/dp/{asin}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/123.0 Safari/537.36",
        "Accept-Language": "en-GB,en;q=0.9",
    }
    try:
        r = requests.get(url, headers=headers, timeout=15)
        if r.status_code != 200:
            return []
        soup = BeautifulSoup(r.text, "html.parser")

        asins = set([asin.upper()])

        # å¸¸è§ data-asin å®¹å™¨
        for tag in soup.find_all(attrs={"data-asin": True}):
            candidate = str(tag.get("data-asin")).strip().upper()
            if re.fullmatch(r"B0[A-Z0-9]{8}", candidate):
                asins.add(candidate)

        # é“¾æ¥å½¢å¼ /dp/B0XXXXXXX/
        for a in soup.find_all("a", href=True):
            m = re.search(r"/dp/(B0[A-Z0-9]{8})", a["href"].upper())
            if m:
                asins.add(m.group(1))

        asins.discard(asin.upper())
        out = list(asins)
        return out[:max_items]
    except Exception:
        return []

# ---------------- Keepa RESTï¼šè·å–å…³è” ASIN ----------------
def _keepa_fetch_related_rest(asin, domain="amazon.co.uk", api_key=None, max_items=200):
    """
    ç›´æ¥ä½¿ç”¨ Keepa REST APIï¼Œä¸ä¾èµ– keepa SDKã€‚å…¼å®¹æ€§æœ€å¥½ã€‚
    è¿”å›ï¼š([ASIN...], é”™è¯¯/æç¤ºæ¶ˆæ¯æˆ– None)
    """
    if not api_key:
        return [], "æœªæ£€æµ‹åˆ° Keepa API Keyï¼Œå·²å›é€€ HTML è§£ææ¨¡å¼ã€‚"

    domain_map = {
        "amazon.co.uk": 2,
        "amazon.com": 1,
        "amazon.de": 3,
        "amazon.fr": 8,
        "amazon.it": 10,
        "amazon.es": 9
    }
    dom = domain_map.get(domain, 2)

    url = "https://api.keepa.com/product"
    params = {
        "key": api_key,
        "domain": dom,
        "asin": asin,
        "history": 0
    }

    try:
        r = requests.get(url, params=params, timeout=25)
        data = r.json()

        if "error" in data and data["error"]:
            return [], f"Keepa API é”™è¯¯: {data['error']}"

        if "products" not in data or not data["products"]:
            return [], "Keepa è¿”å›ä¸ºç©ºï¼Œå¯èƒ½ ASIN æ— æ•°æ®æˆ–æ•°æ®ä¸è¶³ã€‚"

        p = data["products"][0]
        related = set()

        for k in ("alsoBought", "alsoViewed", "frequentlyBoughtTogether", "related"):
            for x in (p.get(k, []) or []):
                xu = str(x).upper()
                if re.fullmatch(r"B0[A-Z0-9]{8}", xu):
                    related.add(xu)

        related.discard(asin.upper())
        out = list(related)[:max_items]

        if not out:
            return out, "Keepa å·²è¿æ¥ï¼Œä½†æœªè¿”å›å…³è” ASINï¼ˆå¯èƒ½æ˜¯æ–°å“æˆ–æ•°æ®ä¸è¶³ï¼‰ã€‚"

        return out, None

    except Exception as e:
        return [], f"Keepa API è¯·æ±‚å¤±è´¥ï¼š{e}"

# ---------------- ç›¸å…³æ€§æ‰“åˆ† + è¿‡æ»¤ ----------------
def score_and_filter(df: pd.DataFrame,
                     include_terms=None,
                     exclude_terms=None,
                     price_min=None,
                     price_max=None,
                     rating_min=None,
                     reviews_min=None):
    """
    å¯¹æŠ“åˆ°çš„ ASIN åšâ€œç›¸å…³æ€§æ‰“åˆ† + è¿‡æ»¤â€
    è§„åˆ™ï¼š
      - æ ‡é¢˜å‘½ä¸­ include_terms åŠ åˆ†ï¼ˆå¤šå‘½ä¸­å¤šåŠ ï¼‰
      - å‘½ä¸­ exclude_terms ç›´æ¥å‰”é™¤
      - ä»·æ ¼/è¯„åˆ†/è¯„è®ºé˜ˆå€¼è¿‡æ»¤ï¼ˆä¸è¾¾æ ‡å‰”é™¤ï¼‰
    è¿”å›ï¼šdf_keptï¼ˆå« RelevanceScoreï¼‰ã€df_droppedï¼ˆè¢«å‰”é™¤é¡¹ï¼‰
    """
    if df is None or df.empty:
        return df, pd.DataFrame()

    work = df.copy()
    # è§„èŒƒåŒ–
    work["title"] = work.get("title", "").fillna("").astype(str).str.lower()

    def contains_any(text, terms):
        text = text or ""
        for t in (terms or []):
            t = t.strip().lower()
            if not t:
                continue
            if t in text:
                return True
        return False

    include_terms = [t.strip().lower() for t in (include_terms or []) if t.strip()]
    exclude_terms = [t.strip().lower() for t in (exclude_terms or []) if t.strip()]

    scores, drops_mask = [], []
    for _, row in work.iterrows():
        title = row.get("title", "")

        # 1) å‘½ä¸­æ’é™¤è¯ â†’ ä¸¢å¼ƒ
        if contains_any(title, exclude_terms):
            scores.append(0)
            drops_mask.append(True)
            continue

        # 2) include è®¡åˆ†
        score = 0
        for t in include_terms:
            if t in title:
                score += 1

        # 3) é˜ˆå€¼è¿‡æ»¤
        price = row.get("price", None)
        rating = row.get("rating", None)
        reviews = row.get("reviews", None)

        drop = False
        if price_min is not None and isinstance(price, (int, float)) and price < price_min:
            drop = True
        if price_max is not None and isinstance(price, (int, float)) and price > price_max:
            drop = True
        if rating_min is not None and (rating is None or (isinstance(rating, (int, float)) and rating < rating_min)):
            drop = True
        if reviews_min is not None and (reviews is None or (isinstance(reviews, (int, float)) and reviews < reviews_min)):
            drop = True

        drops_mask.append(drop)
        scores.append(score)

    work["RelevanceScore"] = scores
    dropped = work.loc[drops_mask].copy()

    kept = work.loc[[not x for x in drops_mask]].copy()
    kept = kept.sort_values(
        by=["RelevanceScore", "reviews", "rating"],
        ascending=[False, False, False],
        kind="mergesort"
    )

    return kept, dropped

# ---------------- UIï¼šè¾“å…¥åŒº ----------------
with st.container():
    cols = st.columns([1,1,1,1])
    with cols[0]:
        domain = st.selectbox("Marketplace", ["amazon.co.uk","amazon.com","amazon.de","amazon.fr","amazon.it","amazon.es"], index=0)
    with cols[1]:
        seed_asin = st.text_input("è¾“å…¥ç«å“ ASINï¼ˆå¦‚ B0D4QMBS75ï¼‰").strip()
    with cols[2]:
        max_items = st.number_input("æœ€å¤šæŠ“å–æ•°é‡", 10, 500, 120, 10)
    with cols[3]:
        prefer_keepa = st.toggle("ä¼˜å…ˆä½¿ç”¨ Keepa (REST)", value=True, help="éœ€åœ¨ Secrets é…ç½® KEEPA_API_KEY æˆ– [keepa].api_keyï¼›æ— åˆ™è‡ªåŠ¨å›é€€ HTML è§£æã€‚")

st.caption(f"ğŸ” Keepa Key çŠ¶æ€ï¼š{'âœ… å·²æ£€æµ‹åˆ°' if KEEPA_KEY else 'âŒ æœªé…ç½®ï¼Œå°†ä½¿ç”¨ HTML å›é€€'}")

# ---------------- UIï¼šç›¸å…³æ€§è¿‡æ»¤å™¨ ----------------
with st.expander("ğŸ§  ç›¸å…³æ€§è¿‡æ»¤å™¨ï¼ˆå»ºè®®å¼€å¯ï¼‰", expanded=True):
    default_includes = "brew, brewing, airlock, ferment, demijohn, bung, grommet, wine, cider, mead, kombucha, heat belt, heat mat, heat pad, fermentation"
    default_excludes = "reptile, terrarium, seed, seedling, plant, pet, dog, cat, car, 12v, water tank, aquarium, vivarium, sous vide, coffee, tea pot"

    colf1, colf2 = st.columns(2)
    with colf1:
        include_terms_str = st.text_input("åŒ…å«å…³é”®è¯ï¼ˆå‘½ä¸­åŠ åˆ†ï¼Œé€—å·åˆ†éš”ï¼‰", value=default_includes)
        price_min = st.number_input("æœ€ä½ä»·æ ¼(Â£)", min_value=0.0, value=10.0, step=0.5)
        rating_min = st.number_input("æœ€ä½è¯„åˆ†", min_value=0.0, max_value=5.0, value=3.8, step=0.1)
    with colf2:
        exclude_terms_str = st.text_input("æ’é™¤å…³é”®è¯ï¼ˆå‘½ä¸­ç›´æ¥å‰”é™¤ï¼Œé€—å·åˆ†éš”ï¼‰", value=default_excludes)
        price_max = st.number_input("æœ€é«˜ä»·æ ¼(Â£)", min_value=0.0, value=60.0, step=0.5)
        reviews_min = st.number_input("æœ€ä½è¯„è®ºæ•°", min_value=0, value=20, step=5)

# ---------------- åŠ¨ä½œ ----------------
if st.button("ğŸš€ å¼€å§‹æŠ“å–", use_container_width=True):
    # æ ¡éªŒ ASIN æ ¼å¼
    if not re.fullmatch(r"[Bb]0[A-Za-z0-9]{8}", seed_asin or ""):
        st.error("è¯·è¾“å…¥åˆæ³•çš„ ASINï¼ˆä»¥ B0 å¼€å¤´ï¼Œå…±10å­—ç¬¦ï¼‰ã€‚")
        st.stop()
    seed_asin = seed_asin.upper()

    # 1) Keepa REST ä¼˜å…ˆ
    related_asins, msg = [], None
    if prefer_keepa and KEEPA_KEY:
        with st.status("ğŸ”— æ­£åœ¨é€šè¿‡ Keepa REST è·å–å…³è” ASIN â€¦", expanded=False):
            related_asins, msg = _keepa_fetch_related_rest(seed_asin, domain=domain, api_key=KEEPA_KEY, max_items=max_items)
            if msg:
                st.write(msg)

    # 2) å›é€€ï¼šHTML è§£æè¯¦æƒ…é¡µæ¨èä½
    if not related_asins:
        with st.status("ğŸ” æ­£åœ¨è§£æç«å“è¯¦æƒ…é¡µæ¨èä½ï¼ˆHTML å›é€€ï¼‰â€¦", expanded=False):
            related_asins = _scrape_related_asins_from_dp(seed_asin, domain=domain, max_items=max_items)
            st.write(f"æ‰¾åˆ°å€™é€‰ ASINï¼š{len(related_asins)}")

    if not related_asins:
        st.error("æœªèƒ½æŠ“åˆ°ç›¸å…³ ASINï¼Œè¯·æ›´æ¢ç«å“æˆ–ç¨åå†è¯•ã€‚")
        st.stop()

    # 3) ä¸ºæ¯ä¸ª ASIN å°½é‡è¡¥ä¿¡æ¯ï¼ˆç§»åŠ¨ç®€é¡µæŠ“å–ï¼‰
    rows = []
    progress = st.progress(0, text="è¡¥å……ä¿¡æ¯ä¸­â€¦")
    for i, a in enumerate(related_asins, start=1):
        snap = _fetch_mobile_product_snapshot(a, domain=domain)
        rows.append(snap)
        progress.progress(int(i/len(related_asins)*100), text=f"ä¿¡æ¯è¡¥å…… {i}/{len(related_asins)}")
    progress.empty()

    df = pd.DataFrame(rows, columns=["asin","title","price","rating","reviews","url"])

    # 4) ç›¸å…³æ€§æ‰“åˆ† + è¿‡æ»¤
    include_terms = [x.strip() for x in include_terms_str.split(",")]
    exclude_terms = [x.strip() for x in exclude_terms_str.split(",")]
    kept, dropped = score_and_filter(
        df,
        include_terms=include_terms,
        exclude_terms=exclude_terms,
        price_min=price_min, price_max=price_max,
        rating_min=rating_min, reviews_min=reviews_min
    )

    st.success(f"æŠ“å–å®Œæˆï¼šå…± {len(df)} æ¡ï¼Œè¿‡æ»¤åå»ºè®®æŠ•æ”¾ {len(kept)} æ¡ï¼Œå‰”é™¤ {len(dropped)} æ¡ã€‚")
    st.subheader("âœ… å»ºè®®æŠ•æ”¾ï¼ˆå·²æŒ‰ç›¸å…³æ€§å¾—åˆ†æ’åºï¼‰")
    st.dataframe(kept, use_container_width=True)

    with st.expander("ğŸ—ƒï¸ è¢«å‰”é™¤ï¼ˆä¾›å¤æ ¸ï¼‰"):
        st.dataframe(dropped, use_container_width=True)

    # 5) å¯¼å‡º CSVï¼ˆå…¨é‡ & å·²è¿‡æ»¤ï¼‰
    csv_full = df.to_csv(index=False).encode("utf-8-sig")
    csv_kept = kept.to_csv(index=False).encode("utf-8-sig")
    today = datetime.now().strftime("%Y%m%d")

    st.download_button("ğŸ“¥ ä¸‹è½½ã€å…¨é‡æŠ“å–ã€‘CSV",
                       data=csv_full,
                       file_name=f"asin_competitors_full_{seed_asin}_{today}.csv",
                       mime="text/csv",
                       use_container_width=True)
    st.download_button("âœ… ä¸‹è½½ã€å·²è¿‡æ»¤æ¨èã€‘CSV",
                       data=csv_kept,
                       file_name=f"asin_competitors_filtered_{seed_asin}_{today}.csv",
                       mime="text/csv",
                       use_container_width=True)

st.markdown("---")
st.caption("æç¤ºï¼šKeepa REST æ›´ç¨³å®šï¼›æœªé…ç½® Keepa æ—¶ä½¿ç”¨ HTML å›é€€å¯èƒ½æŠ“åˆ°èµåŠ©ä½/è·¨ç±»ç›®ï¼Œå»ºè®®ä½¿ç”¨ä¸Šæ–¹ç›¸å…³æ€§è¿‡æ»¤å™¨æ”¶æ•›ã€‚")
