# app.py â€” Competitor ASIN Grabber (Streamlit standalone, fixed)
# åŠŸèƒ½ï¼šè¾“å…¥ä¸€ä¸ªç«å“ ASIN â†’ é€šè¿‡ Keepaï¼ˆä¼˜å…ˆï¼‰æˆ– HTML å›é€€æŠ“å– alsoBought/alsoViewed/related ASIN
# è¾“å‡ºï¼šå°½é‡è¡¥å…¨ æ ‡é¢˜/ä»·æ ¼/è¯„åˆ†/è¯„è®º/é“¾æ¥ â†’ æ”¯æŒ CSV ä¸‹è½½

import os
import re
import requests
import pandas as pd
import streamlit as st
from bs4 import BeautifulSoup
from datetime import datetime

import keepa
st.write("Keepa ç‰ˆæœ¬ï¼š", keepa.__version__)

st.set_page_config(page_title="Competitor ASIN Grabber", layout="wide")
st.title("ğŸ•µï¸ Competitor ASIN Grabber")
st.caption("""
è¾“å…¥ä¸€ä¸ªç«å“ ASINï¼ˆå¦‚ B0D4QMBS75ï¼‰ï¼ŒæŠ“å–è¯¥å•†å“è¯¦æƒ…é¡µçš„ç›¸ä¼¼/ç›¸å…³æ¨èä½çš„ ASINï¼Œ
å¹¶å°½é‡è¡¥å…¨æ ‡é¢˜/ä»·æ ¼/è¯„åˆ†/è¯„è®ºï¼Œæœ€åå¯¼å‡º CSVã€‚

âœ… è‹¥é…ç½®äº† Keepaï¼ˆSecrets ä¸­è®¾ç½® `KEEPA_API_KEY` æˆ– `[keepa].api_key`ï¼‰ï¼Œå°†ä¼˜å…ˆé€šè¿‡ Keepa è·å– alsoBought/alsoViewed/relatedï¼›
â‡ï¸ æœªé…ç½® Keepa æ—¶ä¼šè‡ªåŠ¨å›é€€åˆ° HTML è§£ææ¨¡å¼ã€‚
""")

# ----------------- Keepa Key è¯»å–ï¼ˆå…¼å®¹å¤šç§å†™æ³•ï¼‰ -----------------
def get_keepa_key() -> str:
    """
    è¯»å– Keepa API Keyï¼ˆä¼˜å…ˆ secretsï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼‰ï¼Œæ”¯æŒä¸¤ç§ secrets å†™æ³•ï¼š
    1) KEEPA_API_KEY = "..."
    2) [keepa]
       api_key = "..."
    """
    try:
        key = (
            st.secrets.get("KEEPA_API_KEY", "") or
            (st.secrets.get("keepa", {}) or {}).get("api_key", "") or
            os.environ.get("KEEPA_API_KEY", "")
        )
        return key.strip()
    except Exception:
        return os.environ.get("KEEPA_API_KEY", "").strip()

KEEPA_KEY = get_keepa_key()

# ----------------- å·¥å…·å‡½æ•° -----------------
def _format_price(txt):
    if txt is None:
        return None
    v = re.sub(r"[^\d\.,]", "", str(txt)).replace(",", "")
    try:
        return float(v)
    except Exception:
        return None

def _fetch_mobile_product_snapshot(asin, domain="amazon.co.uk"):
    """
    è®¿é—®äºšé©¬é€Šç§»åŠ¨ç®€é¡µï¼Œå°½é‡å–åˆ°ï¼šæ ‡é¢˜/ä»·æ ¼/æ˜Ÿçº§/è¯„è®ºæ•°ã€‚
    ä»…åšè¡¥å……ï¼Œä¸ä¿è¯100%è·å–ï¼ˆå›é€€ä¹Ÿä¼šè¿”å›åŸºæœ¬ç»“æ„ï¼‰ã€‚
    """
    url = f"https://{domain}/gp/aw/d/{asin}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Linux; Android 11) AppleWebKit/537.36 Mobile Safari/537.36",
        "Accept-Language": "en-GB,en;q=0.9",
    }
    try:
        r = requests.get(url, headers=headers, timeout=12)
        if r.status_code != 200:
            return {"asin": asin, "title": None, "price": None, "rating": None, "reviews": None, "url": f"https://{domain}/dp/{asin}"}
        soup = BeautifulSoup(r.text, "html.parser")

        title_el = soup.select_one("#title")
        title = title_el.get_text(strip=True) if title_el else None

        price = None
        price_el = soup.select_one(".a-color-price") or soup.select_one("#priceblock_ourprice")
        if price_el:
            price = _format_price(price_el.get_text())

        rating = None
        rating_el = soup.select_one(".acr-stars-text") or soup.find(string=re.compile(r"out of 5"))
        if rating_el:
            text = rating_el if isinstance(rating_el, str) else rating_el.get_text()
            m = re.search(r"([\d\.]+)\s*out of 5", text)
            if m:
                try:
                    rating = float(m.group(1))
                except Exception:
                    rating = None

        reviews = None
        rev_el = soup.select_one("#acrCustomerReviewText") or soup.find(string=re.compile(r"ratings"))
        if rev_el:
            text = rev_el if isinstance(rev_el, str) else rev_el.get_text()
            m = re.search(r"([\d,]+)", text)
            if m:
                reviews = int(m.group(1).replace(",", ""))

        return {"asin": asin, "title": title, "price": price, "rating": rating, "reviews": reviews, "url": f"https://{domain}/dp/{asin}"}
    except Exception:
        return {"asin": asin, "title": None, "price": None, "rating": None, "reviews": None, "url": f"https://{domain}/dp/{asin}"}

def _scrape_related_asins_from_dp(asin, domain="amazon.co.uk", max_items=100):
    """
    ç›´æ¥æŠ“å–ç«å“è¯¦æƒ…é¡µï¼Œè§£ææ¨èä½é‡Œçš„ ASINï¼ˆsponsored/related/also viewed ç­‰ï¼‰ã€‚
    ä½œä¸º Keepa ä¸å¯ç”¨æ—¶çš„å›é€€æ–¹æ¡ˆã€‚
    """
    url = f"https://{domain}/dp/{asin}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/123.0 Safari/537.36",
        "Accept-Language": "en-GB,en;q=0.9",
    }
    try:
        r = requests.get(url, headers=headers, timeout=12)
        if r.status_code != 200:
            return []
        soup = BeautifulSoup(r.text, "html.parser")

        asins = set([asin.upper()])

        # å¸¸è§ data-asin å®¹å™¨
        for tag in soup.find_all(attrs={"data-asin": True}):
            candidate = str(tag.get("data-asin")).strip().upper()
            if re.fullmatch(r"B0[A-Z0-9]{8}", candidate):
                asins.add(candidate)

        # é“¾æ¥å½¢å¼ /dp/B0XXXXXXX/
        for a in soup.find_all("a", href=True):
            m = re.search(r"/dp/(B0[A-Z0-9]{8})", a["href"].upper())
            if m:
                asins.add(m.group(1))

        asins.discard(asin.upper())
        out = list(asins)
        return out[:max_items]
    except Exception:
        return []

def _keepa_fetch_related(asin, domain="amazon.co.uk", api_key=None, max_items=200):
    """
    ä½¿ç”¨ Keepa SDK è·å– alsoBought/alsoViewed/related ç­‰å…³è” ASINï¼ˆæ›´ç¨³ã€æ›´å…¨ï¼‰ã€‚
    éœ€è¦ï¼špip install keepaï¼›å¹¶åœ¨ Secrets/ç¯å¢ƒå˜é‡æä¾› api_keyã€‚
    """
    try:
        import keepa
    except Exception:
        return [], "Keepa SDK æœªå®‰è£…ï¼ˆrequirements.txt éœ€åŒ…å« keepa>=1.3.0ï¼‰ï¼Œå·²å›é€€ HTML è§£ææ¨¡å¼ã€‚"

    if not api_key:
        return [], "æœªæ£€æµ‹åˆ° Keepa API Keyï¼Œå·²å›é€€ HTML è§£ææ¨¡å¼ã€‚"

    try:
        api = keepa.Keepa(api_key)
        domain_map = {"amazon.co.uk": 2, "amazon.com": 1, "amazon.de": 3, "amazon.fr": 8, "amazon.it": 10, "amazon.es": 9}
        dom = domain_map.get(domain, 2)
        products = api.query(asin=asin, domain=dom, history=False)
        if not products:
            return [], "Keepa æœªè¿”å›äº§å“ï¼Œå·²å›é€€ HTML è§£ææ¨¡å¼ã€‚"
        p = products[0]
        related = set()
        for k in ("alsoBought", "alsoViewed", "frequentlyBoughtTogether", "related"):
            arr = p.get(k) or []
            for x in arr:
                xu = str(x).upper()
                if re.fullmatch(r"B0[A-Z0-9]{8}", xu):
                    related.add(xu)
        related.discard(asin.upper())
        return list(related)[:max_items], None
    except Exception as e:
        return [], f"Keepa æŸ¥è¯¢å¤±è´¥ï¼ˆ{e}ï¼‰ï¼Œå·²å›é€€ HTML è§£ææ¨¡å¼ã€‚"

# ----------------- UI -----------------
with st.container():
    cols = st.columns([1,1,1,1])
    with cols[0]:
        domain = st.selectbox("Marketplace", ["amazon.co.uk","amazon.com","amazon.de","amazon.fr","amazon.it","amazon.es"], index=0)
    with cols[1]:
        seed_asin = st.text_input("è¾“å…¥ç«å“ ASINï¼ˆå¦‚ B0D4QMBS75ï¼‰").strip()
    with cols[2]:
        max_items = st.number_input("æœ€å¤šæŠ“å–æ•°é‡", 10, 500, 120, 10)
    with cols[3]:
        prefer_keepa = st.toggle("ä¼˜å…ˆä½¿ç”¨ Keepa", value=True, help="éœ€åœ¨ Secrets é…ç½® KEEPA_API_KEY æˆ– [keepa].api_keyï¼›æ— åˆ™è‡ªåŠ¨å›é€€ HTML è§£æã€‚")

# å°æç¤ºæ˜¾ç¤ºå¯†é’¥çŠ¶æ€ï¼ˆå¯æ³¨é‡Šæ‰ï¼‰
st.caption(f"ğŸ” Keepa Key çŠ¶æ€ï¼š{'âœ… å·²æ£€æµ‹åˆ°' if KEEPA_KEY else 'âŒ æœªé…ç½®ï¼Œå°†ä½¿ç”¨ HTML å›é€€'}")

if st.button("ğŸš€ å¼€å§‹æŠ“å–", use_container_width=True):
    # æ ¡éªŒ ASIN æ ¼å¼
    if not re.fullmatch(r"[Bb]0[A-Za-z0-9]{8}", seed_asin or ""):
        st.error("è¯·è¾“å…¥åˆæ³•çš„ ASINï¼ˆä»¥ B0 å¼€å¤´ï¼Œå…±10å­—ç¬¦ï¼‰ã€‚")
        st.stop()
    seed_asin = seed_asin.upper()

    related_asins, keepa_msg = [], None

    # 1) Keepa ä¼˜å…ˆ
    if prefer_keepa:
        related_asins, keepa_msg = _keepa_fetch_related(seed_asin, domain=domain, api_key=KEEPA_KEY, max_items=max_items)
        if keepa_msg:
            st.warning(keepa_msg)

    # 2) å›é€€ï¼šHTML è§£æè¯¦æƒ…é¡µæ¨èä½
    if not related_asins:
        with st.status("ğŸ” æ­£åœ¨è§£æç«å“è¯¦æƒ…é¡µçš„æ¨èä½ â€¦", expanded=False):
            related_asins = _scrape_related_asins_from_dp(seed_asin, domain=domain, max_items=max_items)
            st.write(f"æ‰¾åˆ°å€™é€‰ ASINï¼š{len(related_asins)}")

    if not related_asins:
        st.error("æœªèƒ½æŠ“åˆ°ç›¸å…³ ASINï¼Œè¯·æ›´æ¢ç«å“æˆ–ç¨åå†è¯•ã€‚")
        st.stop()

    # 3) ä¸ºæ¯ä¸ª ASIN å°½é‡è¡¥ä¿¡æ¯ï¼ˆç§»åŠ¨ç®€é¡µæŠ“å–ï¼‰
    rows = []
    progress = st.progress(0, text="è¡¥å……ä¿¡æ¯ä¸­â€¦")
    for i, a in enumerate(related_asins, start=1):
        snap = _fetch_mobile_product_snapshot(a, domain=domain)
        rows.append(snap)
        progress.progress(int(i/len(related_asins)*100), text=f"ä¿¡æ¯è¡¥å…… {i}/{len(related_asins)}")
    progress.empty()

    df = pd.DataFrame(rows, columns=["asin","title","price","rating","reviews","url"])
    st.success(f"æŠ“å–å®Œæˆï¼šå…± {len(df)} æ¡ã€‚")
    st.dataframe(df, use_container_width=True)

    # 4) å¯¼å‡º CSV
    csv_data = df.to_csv(index=False).encode("utf-8-sig")
    today = datetime.now().strftime("%Y%m%d")
    st.download_button(
        "ğŸ“¥ ä¸‹è½½ CSV",
        data=csv_data,
        file_name=f"asin_competitors_{seed_asin}_{today}.csv",
        mime="text/csv",
        use_container_width=True
    )

st.markdown("---")
st.caption("æç¤ºï¼šæœªé…ç½® Keepa æ—¶å°†ä½¿ç”¨ HTML å›é€€ï¼Œå¯èƒ½å—é¡µé¢ç»“æ„å½±å“æŠ“å–ç‡è¾ƒä½ï¼›å»ºè®®åœ¨ Secrets é…ç½® Keepa æå‡ç¨³å®šæ€§ä¸è¦†ç›–ç‡ã€‚")
